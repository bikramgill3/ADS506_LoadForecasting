---
title: "ADS506 - Group Project - ERCOT Load Forecasting"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}

library(astsa)
library(ggplot2)
library(readxl)
library(tidyverse)
library(ggdark)
library(reshape2) 
library(xts)
library(dplyr)
library(EnvStats)
library(forecast)
library(rugarch)
```

Please see code blocks below which have been used to load, prep, transform and plot our data.

This will serve as our initial pre-processing, which we can further analyze for our modelling phase and our paper.

Further analysis will also be performed as we dive deeper into our paper and final code. 


```{r dataload}
load17.df <- read_excel('Native_Load_2017.xlsx')
load18.df <- read_excel('Native_Load_2018.xlsx')
load19.df <- read_excel('Native_Load_2019.xlsx')
load20.df <- read_excel('Native_Load_2020.xlsx')
load21.df <- read_excel('Native_Load_2021.xlsx')
```


```{r dataprep}
## The load dataset for 2017 had a space in the Timestamp column, preventing the binding of the four years
colnames(load17.df)[1] <- "HourEnding"

## Using bind_rows from tidyverse, the data from 2017-2020 was merged.
load_4_year <- bind_rows(load17.df,load18.df,load19.df,load20.df)
sum(is.na(load_4_year))

load_4_year <- load_4_year[c("HourEnding","ERCOT")]



## Using strptime, the time variable data type was set. 
load_4_year$HourEnding <- as.POSIXct(strptime(load_4_year$HourEnding, format="%m/%d/%Y %H:%M"))

#Remove NA's which arise due to issues with daylight savings (1 record in each year)
load_4_year <- na.omit(load_4_year)

## Converting to a time series
ts_load <- xts(load_4_year, load_4_year$HourEnding)
ts_load <- ts_load[,-1]
head(ts_load)
```



It is clear that a min max normalization scalar is not a usable option as it does not account for the mean. The graph is still visually the same.




```{r bg_arima}

##### Bikram: notes here; im going to plot the P/ACF's, which should show if we need to difference, AR(x) and MA(x).

### From there, will fit the ARIMA model, forecast 2021 and then plot the dataset vs forecast
library(ggplot2)
library(ggfortify)

par(mfrow = c(4,1)) 
acf2(load_4_year$ERCOT, main = "Raw Data")
acf2(diff(load_4_year$ERCOT), main = "First-Order Difference")
acf2(diff(diff(load_4_year$ERCOT)), main = "Second-Order Difference")
acf2(diff(log(load_4_year$ERCOT),24), main = "Seasonally differenced logs")

### We see clear cyclicality in the raw data, first-order difference and second order difference. 
### When observing the differences, the trend can be seen around lag 24, indiciating this is a daily autocorrelatioj (e.g. power demand at any given hour today will be highly correlated to the demand at the same time 24, 48, 72 hours ago etc.)

## Seasonally differencing produces a series that can be modelled.
### Based on the seasonally differenced P/ACF, the ACF tails off while the P/ACF cuts off. This indicates an AR(p) model. 

log_load <- log(load_4_year$ERCOT)

```





```{r bg_arima2}

### Fit ARIMA Model

bg_arima <- arima(log_load, order = c(24, 0, 0))
bg_arima

bg_forecast <- forecast(bg_arima, 60, level = c(.95))
bg_forecast


# Plotting my forecasted loads
plot(bg_forecast, type = "p", xlim= c(35000, 35120))

```




```{r GARCH Model}

# Model specification of a GARCH constant model
garchSpec = ugarchspec(
           variance.model=list(model="sGARCH",
                               garchOrder=c(1,1)),
           mean.model=list(arimaorder=c(24,24,0)), 
           distribution.model="std")

# Fitting the model
garchFit = ugarchfit(spec=garchSpec, data=log_load, out.sample = 20)
garchFit


# Plot the different useful graphs for the model estimation
plot(garchFit, which="all")
```

***Model Comments and Findings***

*The first table on the first part of the estimation results (Refer to "Optimal parameters" table) shows the optimal estimated parameters. Which means the significance of the estimated parameter.* 

*The second table (refer to "Information criteria"). Shows the Akaike (AIC), Bayes (BIC), Shibata and Hannan-Quinn criteria for the model estimation. Basically the lower these values, the better the model is in terms of fitting. And we can see the results we have are in the (-4) range, which is good.*


*The third table presents the Ljung-Box test for testing the serial correlation of the error terms. The null hypothesis states there is no serial correlation of the error terms. Basically, if the p-value is lower than 5%, the null hypothesis is rejected. Our results show that our p-value is higher than 5% on the on "Standardized Squared Residuals", meaning that there is no serial correlation of the error term.*


*The last table is yet another interesting one to check (refer to "Adjusted Pearson Goodness of Fit"), it measures the goodness of fit of the error. The null hypothesis says that the conditional error term follows a normal distribution. If the p-value is lower than 5%, the null hypothesis is rejected. Our results show three of the p-value higher than 5% and one lower.*







```{r ARMA model}

#Fitting the AR Model to log_load

AR <- arima(log_load, order = c(1,0,0))
print(AR)

ts.plot(load_4_year$ERCOT)
AR_fit <- load_4_year$ERCOT - residuals(AR)
AR_fit2 <- log_load - residuals(AR)
plot(AR_fit2, type = "p", col = 4, lty = 2, xlim= c(35000, 35120))

#Using predict() to make a 1-step forecast
predict_AR <- predict(AR)

#Obtaining the 1-step forecast using $pred[1]
predict_AR$pred[1]

#ALternatively Using predict to make 1-step through 60-step forecasts
predict(AR, n.ahead = 60)

plot(load_4_year)
AR_forecast <- predict(AR, n.ahead = 60)$pred
AR_forecast_se <- predict(AR, n.ahead = 60)$se
plot(log_load)
points(AR_forecast, type = "l", col = 2) # running into an error in plotting the follow on forecasted values
points(AR_forecast - 2*AR_forecast_se, type = "l", col = 2, lty = 2)
points(AR_forecast + 2*AR_forecast_se, type = "l", col = 2, lty = 2)

#Fitting the MA model to log_load
MA <- arima(log_load, order = c(0,0,1))
print(MA)

MA_fit <- log_load - resid(MA)
plot(MA_fit, type = "p", col = 2, lty = 2, xlim= c(35000, 35120))

#Making a 1-step forecast based on MA
predict_MA <- predict(MA)

#Obtaining the 1-step forecast using $pred[1]
predict_MA$pred[1]

#Alternately Making a 1-step through 60-step forecast based on MA
predict(MA,n.ahead=60)

MA_forecast <- predict(MA, n.ahead = 60)$pred
MA_forecast_se <- predict(MA, n.ahead = 60)$se
plot(log_load)

plot(MA_forecast, type = "p", col = 2) # running into an error in plotting the follow on forecasted values
points(AR_forecast - 2*AR_forecast_se, type = "l", col = 2, lty = 2)
points(AR_forecast + 2*AR_forecast_se, type = "l", col = 2, lty = 2)

# Find correlation between AR_fit and MA_fit
cor(AR_fit, MA_fit)

# Find AIC of AR
AIC(AR)

# Find AIC of MA
AIC(MA)

# Find BIC of AR
BIC(AR)

# Find BIC of MA
BIC(MA)

#Given the smaller value of the AIC and BIC in the MA model we should use that
```


```{r ARIMA model}
ARIMA_model1 <- auto.arima(log_load) # auto arima tries to select the best model

ARIMA_model1

# using forecast() to forecast the next 60 points
# with a 95% CI
MyARIMAForecast <- forecast(ARIMA_model1, 60, level = c(.95))
MyARIMAForecast


# Plotting my forecasted loads
plot(MyARIMAForecast, type = "p", xlim= c(35000, 35120))
```



